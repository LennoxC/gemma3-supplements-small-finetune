{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1h77TYIyDvSYg8rYt9OA1EH9EmowYMknu",
   "authorship_tag": "ABX9TyP7w89+EmKLajUcv2yjTLNE",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gemma3-4b fine-tune for food and beverage label OCR-VQA"
   ],
   "metadata": {
    "id": "C4SwckN0bDGt"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ElA7flCNZbtK",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:17.093887Z",
     "start_time": "2025-08-15T03:31:02.346220Z"
    }
   },
   "source": [
    "#%pip install torch tensorboard\n",
    "#%pip install transformers datasets accelerate evaluate trl protobuf sentencepiece\n",
    "#%pip install flash-attn\n",
    "#%pip install accelerate peft"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: torch in /usr/pkg/lib/python3.12/site-packages (2.6.0+cu126)\r\n",
      "Requirement already satisfied: tensorboard in ./.local/lib/python3.12/site-packages (2.19.0)\r\n",
      "Requirement already satisfied: filelock in /usr/pkg/lib/python3.12/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/pkg/lib/python3.12/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/pkg/lib/python3.12/site-packages (from torch) (80.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/pkg/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/pkg/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.12/site-packages (from torch) (2025.3.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/pkg/lib/python3.12/site-packages (from torch) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/pkg/lib/python3.12/site-packages (from torch) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/pkg/lib/python3.12/site-packages (from torch) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/pkg/lib/python3.12/site-packages (from torch) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/pkg/lib/python3.12/site-packages (from torch) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/pkg/lib/python3.12/site-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/pkg/lib/python3.12/site-packages (from torch) (12.6.85)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/pkg/lib/python3.12/site-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/pkg/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (2.2.2)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (1.70.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (3.8)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.local/lib/python3.12/site-packages (from tensorboard) (2.1.3)\r\n",
      "Requirement already satisfied: packaging in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (5.29.4)\r\n",
      "Requirement already satisfied: six>1.9 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (1.17.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/pkg/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.12/site-packages (4.55.2)\r\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.12/site-packages (4.0.0)\r\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.12/site-packages (1.10.0)\r\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.12/site-packages (0.4.5)\r\n",
      "Requirement already satisfied: trl in ./.local/lib/python3.12/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: protobuf in /usr/pkg/lib/python3.12/site-packages (5.29.4)\r\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.12/site-packages (0.2.1)\r\n",
      "Requirement already satisfied: filelock in /usr/pkg/lib/python3.12/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.12/site-packages (from transformers) (0.34.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers) (2.1.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/pkg/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/pkg/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/pkg/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/pkg/lib/python3.12/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers) (0.21.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/pkg/lib/python3.12/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/pkg/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/pkg/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/pkg/lib/python3.12/site-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/pkg/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: psutil in /usr/pkg/lib/python3.12/site-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/pkg/lib/python3.12/site-packages (from accelerate) (2.6.0+cu126)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/pkg/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: idna>=2.0 in /usr/pkg/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/pkg/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/pkg/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/pkg/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\r\n",
      "Requirement already satisfied: setuptools in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/pkg/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/pkg/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/pkg/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/pkg/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/pkg/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/pkg/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting flash-attn\r\n",
      "  Using cached flash_attn-2.8.2.tar.gz (8.2 MB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py egg_info\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[21 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m /tmp/pip-install-7e6fg1wa/flash-attn_25a242632d1745688fee32b11463a655/setup.py:106: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\r\n",
      "  \u001B[31m   \u001B[0m   warnings.warn(\r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 2, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"<pip-setuptools-caller>\", line 35, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"/tmp/pip-install-7e6fg1wa/flash-attn_25a242632d1745688fee32b11463a655/setup.py\", line 227, in <module>\r\n",
      "  \u001B[31m   \u001B[0m     CUDAExtension(\r\n",
      "  \u001B[31m   \u001B[0m   File \"/usr/pkg/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1130, in CUDAExtension\r\n",
      "  \u001B[31m   \u001B[0m     library_dirs += library_paths(device_type=\"cuda\")\r\n",
      "  \u001B[31m   \u001B[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/usr/pkg/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1264, in library_paths\r\n",
      "  \u001B[31m   \u001B[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\r\n",
      "  \u001B[31m   \u001B[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/usr/pkg/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2525, in _join_cuda_home\r\n",
      "  \u001B[31m   \u001B[0m     raise OSError('CUDA_HOME environment variable is not set. '\r\n",
      "  \u001B[31m   \u001B[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m torch.__version__  = 2.6.0+cu126\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\r\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\r\n",
      "\u001B[?25hNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.12/site-packages (1.10.0)\r\n",
      "Requirement already satisfied: peft in ./.local/lib/python3.12/site-packages (0.17.0)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.local/lib/python3.12/site-packages (from accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/pkg/lib/python3.12/site-packages (from accelerate) (25.0)\r\n",
      "Requirement already satisfied: psutil in /usr/pkg/lib/python3.12/site-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/pkg/lib/python3.12/site-packages (from accelerate) (6.0.2)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/pkg/lib/python3.12/site-packages (from accelerate) (2.6.0+cu126)\r\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./.local/lib/python3.12/site-packages (from accelerate) (0.34.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from accelerate) (0.6.2)\r\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.12/site-packages (from peft) (4.55.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/pkg/lib/python3.12/site-packages (from peft) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/pkg/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\r\n",
      "Requirement already satisfied: requests in /usr/pkg/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/pkg/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\r\n",
      "Requirement already satisfied: setuptools in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/pkg/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/pkg/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/pkg/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/pkg/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/pkg/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/pkg/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/pkg/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/pkg/lib/python3.12/site-packages (from transformers->peft) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.12/site-packages (from transformers->peft) (0.21.4)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:19.111630Z",
     "start_time": "2025-08-15T03:31:17.118062Z"
    }
   },
   "cell_type": "code",
   "source": "#%pip install tf-keras",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: tf-keras in ./.local/lib/python3.12/site-packages (2.19.0)\r\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in ./.local/lib/python3.12/site-packages (from tf-keras) (2.19.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.12.23)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (80.9.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.14.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.70.0)\r\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./.local/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.7.0)\r\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in ./.local/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/pkg/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.local/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/pkg/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/pkg/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/pkg/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/pkg/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.6.15)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/pkg/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/pkg/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/pkg/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/pkg/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/pkg/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\r\n",
      "Requirement already satisfied: namex in /usr/pkg/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/pkg/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.13.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/pkg/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/pkg/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/pkg/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/pkg/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "import os",
   "metadata": {
    "id": "duB2IDCaeeOs",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:19.136426Z",
     "start_time": "2025-08-15T03:31:19.133681Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "hf_token = os.getenv('HF_TOKEN')",
   "metadata": {
    "id": "xh2WMSV4bi-h",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:19.406965Z",
     "start_time": "2025-08-15T03:31:19.241976Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:19.474513Z",
     "start_time": "2025-08-15T03:31:19.470374Z"
    }
   },
   "cell_type": "code",
   "source": "#%env HF_HOME=/local/scratch/crowelenn-aiml339/",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/local/scratch/crowelenn-aiml339/\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "base_model = \"google/gemma-3-4b-it\"\n",
    "checkpoint_dir = \"/local/scratch/crowelenn-aiml339/checkpoints\"\n",
    "learning_rate = 5e-5"
   ],
   "metadata": {
    "id": "awDbCORgcbg8",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:19.540752Z",
     "start_time": "2025-08-15T03:31:19.537772Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tensorboard setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:21.619931Z",
     "start_time": "2025-08-15T03:31:19.601834Z"
    }
   },
   "cell_type": "code",
   "source": "#%pip install tensorboard",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: tensorboard in ./.local/lib/python3.12/site-packages (2.19.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (2.2.2)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (1.70.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (3.8)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.local/lib/python3.12/site-packages (from tensorboard) (2.1.3)\r\n",
      "Requirement already satisfied: packaging in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (5.29.4)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (80.9.0)\r\n",
      "Requirement already satisfied: six>1.9 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (1.17.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/pkg/lib/python3.12/site-packages (from tensorboard) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/pkg/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "system_message = \"You are a quality control robot responsible for monitoring the quality of supplement labels.\"\n",
    "user_prompt = \"\"\"Using primarily the text contained in the attached label supplement image, answer the list of questions in the <QUESTIONS> tags.\n",
    "Answer concisely in a JSON format with no preamble, allowing the response to easily be parsed. An example response would be:\n",
    "{\n",
    "  \"brand\": \"label supplelments co\",\n",
    "  \"contents\": 120\n",
    "}\n",
    "\n",
    "<QUESTIONS>\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "6pIe6Tfzt_wi",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:21.660655Z",
     "start_time": "2025-08-15T03:31:21.657670Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": sample[\"questions\"]\n",
    "                        #\"text\": user_prompt.format(\n",
    "                        #    questions=sample[\"questions\"]\n",
    "                        #),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": sample[\"image\"],\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": sample[\"answers\"]}],\n",
    "            },\n",
    "        ],\n",
    "    }"
   ],
   "metadata": {
    "id": "WgClnPnSt1cU",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:21.774517Z",
     "start_time": "2025-08-15T03:31:21.769864Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "import json, random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class OCRVQADataset(Dataset):\n",
    "    def __init__(self, jsonl_file, transform=None, min_q=1, max_q=4):\n",
    "        with open(jsonl_file, 'r') as f:\n",
    "            self.samples = [json.loads(line) for line in f]\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "        self.min_q = min_q\n",
    "        self.max_q = max_q\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "\n",
    "        # Keep as PIL so process_vision_info works later\n",
    "        image_path = \"AIML339/supplements_small/images/\" + sample[\"image\"]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        qa_pairs = sample[\"qas\"]\n",
    "        k = random.randint(self.min_q, min(self.max_q, len(qa_pairs)))\n",
    "        chosen_pairs = random.sample(qa_pairs, k)\n",
    "\n",
    "        questions_str = (\n",
    "            user_prompt\n",
    "            + \"; \".join(f\"Question: {p['q']} This corresponds to JSON key {p['k']}\" for p in chosen_pairs)\n",
    "            + \"</QUESTIONS>\"\n",
    "        )\n",
    "        answers_dict = {p['k']: p['a'] for p in chosen_pairs}\n",
    "        answers_str = json.dumps(answers_dict, ensure_ascii=False)\n",
    "\n",
    "        return {\n",
    "            \"image\": image,  # PIL\n",
    "            \"questions\": questions_str,\n",
    "            \"answers\": answers_str\n",
    "        }"
   ],
   "metadata": {
    "id": "YT0xw4KSgZ5e",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:26.323065Z",
     "start_time": "2025-08-15T03:31:21.919834Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def process_vision_info(messages: list[dict]) -> list[Image.Image]:\n",
    "    image_inputs = []\n",
    "    for msg in messages:\n",
    "        content = msg.get(\"content\", [])\n",
    "        if not isinstance(content, list):\n",
    "            content = [content]\n",
    "\n",
    "        for element in content:\n",
    "            if isinstance(element, dict) and (\n",
    "                \"image\" in element or element.get(\"type\") == \"image\"\n",
    "            ):\n",
    "                img = element.get(\"image\", element)\n",
    "                if isinstance(img, str):\n",
    "                    img = Image.open(img).convert(\"RGB\")\n",
    "                elif not isinstance(img, Image.Image):\n",
    "                    raise ValueError(f\"Unsupported image type: {type(img)}\")\n",
    "                image_inputs.append(img)\n",
    "    return image_inputs\n"
   ],
   "metadata": {
    "id": "kISLJ2tduRvI",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:26.343711Z",
     "start_time": "2025-08-15T03:31:26.337368Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = r'AIML339/supplements_small/output.jsonl'\n",
    "dataset_obj = OCRVQADataset(dataset_path)"
   ],
   "metadata": {
    "id": "OMrFZ6siIKCd",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:26.494017Z",
     "start_time": "2025-08-15T03:31:26.465495Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set split sizes\n",
    "total_size = len(dataset_obj)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Use a generator with a manual seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(42)"
   ],
   "metadata": {
    "id": "MqKFo5thF8_B",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:26.582283Z",
     "start_time": "2025-08-15T03:31:26.578289Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset_obj, [train_size, val_size, test_size], generator=generator\n",
    ")\n",
    "\n",
    "train_dataset_fmt = [format_data(sample) for sample in train_dataset]\n",
    "\n",
    "print(train_dataset_fmt[100])"
   ],
   "metadata": {
    "id": "iKvgPfNGiSzq",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:31:42.204748Z",
     "start_time": "2025-08-15T03:31:26.653270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a quality control robot responsible for monitoring the quality of supplement labels.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Using primarily the text contained in the attached label supplement image, answer the list of questions in the <QUESTIONS> tags.\\nAnswer concisely in a JSON format with no preamble, allowing the response to easily be parsed. An example response would be:\\n{\\n  \"brand\": \"label supplelments co\",\\n  \"contents\": 120\\n}\\n\\n<QUESTIONS>\\nQuestion: What is the name of the brand? This corresponds to JSON key brand; Question: What is the numeric component of the product contents? This corresponds to JSON key contents</QUESTIONS>'}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1339x1150 at 0x558FD8D08400>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '{\"brand\": \"BNRG Bionutritional Research Group\", \"contents\": \"1\"}'}]}]}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "writer = SummaryWriter(log_dir=\"./logs\")\n",
    "\n",
    "# Hugging Face model id\n",
    "model_id = \"google/gemma-3-4b-it\" # or `google/gemma-3-12b-pt`, `google/gemma-3-27-pt`\n",
    "\n",
    "# Check if GPU benefits from bfloat16\n",
    "#if torch.cuda.get_device_capability()[0] < 8:\n",
    "#    raise ValueError(\"GPU does not support bfloat16, please use a GPU that supports bfloat16.\")\n",
    "\n",
    "# Define model init arguments\n",
    "#model_kwargs = dict(\n",
    "#    attn_implementation=\"eager\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
    "#    torch_dtype=torch.bfloat16 # What torch dtype to use, defaults to auto\n",
    "#)\n",
    "\n",
    "# Load model and tokenizer\n",
    "#model = AutoModelForImageTextToText.from_pretrained(model_id, **model_kwargs)\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model)"
   ],
   "metadata": {
    "id": "yraPRRaI5oLt",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:01.967836Z",
     "start_time": "2025-08-15T03:31:42.285552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-15 15:31:45.676895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755228705.696087  182313 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755228705.700038  182313 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755228705.711615  182313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755228705.711632  182313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755228705.711634  182313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755228705.711637  182313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-15 15:31:45.716866: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.81it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:33:50.925515Z",
     "start_time": "2025-08-15T03:33:50.921724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Visible devices:\", accelerator.state.num_processes)\n",
    "print(\"Local device:\", accelerator.device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible devices: 1\n",
      "Local device: cuda\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "    target_modules=\"all-linear\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    modules_to_save=[\"lm_head\", \"embed_tokens\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "metadata": {
    "id": "v3KB38Mj56R-",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:06.162431Z",
     "start_time": "2025-08-15T03:32:04.243953Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "from trl import SFTConfig\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=\"gemma-supplements-small\",       # directory to save and repository id\n",
    "    num_train_epochs=1,                         # number of training epochs\n",
    "    per_device_train_batch_size=1,              # batch size per device during training\n",
    "    gradient_accumulation_steps=4,              # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,                # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    logging_dir=\"./logs\",                       # tensorboard output\n",
    "    logging_steps=5,                            # log every 5 steps\n",
    "    save_strategy=\"epoch\",                      # save checkpoint every epoch\n",
    "    learning_rate=2e-4,                         # learning rate, based on QLoRA paper\n",
    "    bf16=True,                                  # use bfloat16 precision\n",
    "    max_grad_norm=0.3,                          # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.03,                          # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"constant\",               # use constant learning rate scheduler\n",
    "    push_to_hub=True,                           # push model to hub\n",
    "    report_to=\"tensorboard\",                    # report metrics to tensorboard\n",
    "    gradient_checkpointing_kwargs={\n",
    "        \"use_reentrant\": False\n",
    "    },  # use reentrant checkpointing\n",
    "    dataset_text_field=\"\",                      # need a dummy field for collator\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},  # important for collator\n",
    ")\n",
    "args.remove_unused_columns = False # important for collator\n",
    "#args.dataloader_pin_memory = False\n",
    "'''\n",
    "# Create a data collator to encode text and image pairs\n",
    "def collate_fn(examples):\n",
    "    texts, images = [], []\n",
    "    for example in examples:\n",
    "        image_inputs = process_vision_info(example[\"messages\"])\n",
    "        text = processor.apply_chat_template(\n",
    "            example[\"messages\"], add_generation_prompt=False, tokenize=False\n",
    "        )\n",
    "        texts.append(text.strip())\n",
    "        images.append(image_inputs)\n",
    "\n",
    "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    image_token_id = [\n",
    "        processor.tokenizer.convert_tokens_to_ids(\n",
    "            processor.tokenizer.special_tokens_map[\"boi_token\"]\n",
    "        )\n",
    "    ]\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    labels[labels == image_token_id] = -100\n",
    "    labels[labels == 262144] = -100\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch  # keep on CPU, Accelerator will move to GPU"
   ],
   "metadata": {
    "id": "UAObWZGX568Q",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:08.542465Z",
     "start_time": "2025-08-15T03:32:08.532951Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset_fmt,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ],
   "metadata": {
    "id": "v02de0fu6P1w",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:10.937346Z",
     "start_time": "2025-08-15T03:32:10.932860Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:13.227155Z",
     "start_time": "2025-08-15T03:32:13.206227Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:19.218721Z",
     "start_time": "2025-08-15T03:32:15.517104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "num_epochs = 1\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss if hasattr(outputs, \"loss\") else loss_fn(outputs.logits, batch[\"labels\"])\n",
    "\n",
    "        # Scale loss if using gradient accumulation\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            # Log to TensorBoard\n",
    "            writer.add_scalar(\"train/loss\", loss.item() * gradient_accumulation_steps, global_step)\n",
    "\n",
    "    # Optional: save checkpoint at epoch end\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(f\"gemma-supplements-small/epoch{epoch+1}\")"
   ],
   "metadata": {
    "id": "y9b_q6xU6STw",
    "ExecuteTime": {
     "end_time": "2025-08-15T03:32:25.236464Z",
     "start_time": "2025-08-15T03:32:21.485096Z"
    }
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 15.60 GiB of which 589.19 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 854.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[32m     11\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m         outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m         loss = outputs.loss \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(outputs, \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m loss_fn(outputs.logits, batch[\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     15\u001B[39m         \u001B[38;5;66;03m# Scale loss if using gradient accumulation\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:818\u001B[39m, in \u001B[36mconvert_outputs_to_fp32.<locals>.forward\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    817\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(*args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m818\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:806\u001B[39m, in \u001B[36mConvertOutputsToFp32.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    805\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m806\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001B[39m, in \u001B[36mautocast_decorator.<locals>.decorate_autocast\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     41\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_autocast\u001B[39m(*args, **kwargs):\n\u001B[32m     43\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/peft/peft_model.py:1850\u001B[39m, in \u001B[36mPeftModelForCausalLM.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[39m\n\u001B[32m   1848\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._enable_peft_forward_hooks(**kwargs):\n\u001B[32m   1849\u001B[39m         kwargs = {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.special_peft_forward_args}\n\u001B[32m-> \u001B[39m\u001B[32m1850\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1851\u001B[39m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1852\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1853\u001B[39m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1854\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1855\u001B[39m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1856\u001B[39m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1857\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1858\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1859\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1861\u001B[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001B[32m   1862\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1863\u001B[39m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:222\u001B[39m, in \u001B[36mBaseTuner.forward\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any):\n\u001B[32m--> \u001B[39m\u001B[32m222\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:1076\u001B[39m, in \u001B[36mGemma3ForConditionalGeneration.forward\u001B[39m\u001B[34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **lm_kwargs)\u001B[39m\n\u001B[32m   1071\u001B[39m output_hidden_states = (\n\u001B[32m   1072\u001B[39m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.output_hidden_states\n\u001B[32m   1073\u001B[39m )\n\u001B[32m   1074\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m-> \u001B[39m\u001B[32m1076\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1077\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1078\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1079\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1080\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1081\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1082\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1083\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1084\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1085\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1086\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1087\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1088\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1089\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1090\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mlm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1091\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1093\u001B[39m hidden_states = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1094\u001B[39m \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    957\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    958\u001B[39m     return_dict = return_dict_passed\n\u001B[32m--> \u001B[39m\u001B[32m959\u001B[39m output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    961\u001B[39m     output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:899\u001B[39m, in \u001B[36mGemma3Model.forward\u001B[39m\u001B[34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **lm_kwargs)\u001B[39m\n\u001B[32m    897\u001B[39m \u001B[38;5;66;03m# Merge text and images\u001B[39;00m\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pixel_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m899\u001B[39m     image_features = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_image_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    900\u001B[39m     image_features = image_features.to(inputs_embeds.device, inputs_embeds.dtype)\n\u001B[32m    901\u001B[39m     special_image_mask = \u001B[38;5;28mself\u001B[39m.get_placeholder_mask(\n\u001B[32m    902\u001B[39m         input_ids, inputs_embeds=inputs_embeds, image_features=image_features\n\u001B[32m    903\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:797\u001B[39m, in \u001B[36mGemma3Model.get_image_features\u001B[39m\u001B[34m(self, pixel_values)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_image_features\u001B[39m(\u001B[38;5;28mself\u001B[39m, pixel_values: torch.Tensor) -> torch.Tensor:\n\u001B[32m    788\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    789\u001B[39m \u001B[33;03m    Projects the last hidden state from the vision model into language model space.\u001B[39;00m\n\u001B[32m    790\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    795\u001B[39m \u001B[33;03m        image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).\u001B[39;00m\n\u001B[32m    796\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m797\u001B[39m     vision_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvision_tower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m)\u001B[49m.last_hidden_state\n\u001B[32m    798\u001B[39m     image_features = \u001B[38;5;28mself\u001B[39m.multi_modal_projector(vision_outputs)\n\u001B[32m    799\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m image_features\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    957\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    958\u001B[39m     return_dict = return_dict_passed\n\u001B[32m--> \u001B[39m\u001B[32m959\u001B[39m output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    961\u001B[39m     output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:856\u001B[39m, in \u001B[36mSiglipVisionModel.forward\u001B[39m\u001B[34m(self, pixel_values, output_attentions, output_hidden_states, interpolate_pos_encoding)\u001B[39m\n\u001B[32m    826\u001B[39m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[32m    827\u001B[39m \u001B[38;5;129m@auto_docstring\u001B[39m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m   (...)\u001B[39m\u001B[32m    833\u001B[39m     interpolate_pos_encoding: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    834\u001B[39m ) -> BaseModelOutputWithPooling:\n\u001B[32m    835\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    836\u001B[39m \u001B[33;03m    Examples:\u001B[39;00m\n\u001B[32m    837\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    853\u001B[39m \u001B[33;03m    >>> pooled_output = outputs.pooler_output  # pooled features\u001B[39;00m\n\u001B[32m    854\u001B[39m \u001B[33;03m    ```\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m856\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvision_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    857\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    858\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    859\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    860\u001B[39m \u001B[43m        \u001B[49m\u001B[43minterpolate_pos_encoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterpolate_pos_encoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    861\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    957\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    958\u001B[39m     return_dict = return_dict_passed\n\u001B[32m--> \u001B[39m\u001B[32m959\u001B[39m output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    961\u001B[39m     output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:763\u001B[39m, in \u001B[36mSiglipVisionTransformer.forward\u001B[39m\u001B[34m(self, pixel_values, output_attentions, output_hidden_states, interpolate_pos_encoding)\u001B[39m\n\u001B[32m    757\u001B[39m output_hidden_states = (\n\u001B[32m    758\u001B[39m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.output_hidden_states\n\u001B[32m    759\u001B[39m )\n\u001B[32m    761\u001B[39m hidden_states = \u001B[38;5;28mself\u001B[39m.embeddings(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)\n\u001B[32m--> \u001B[39m\u001B[32m763\u001B[39m encoder_outputs: BaseModelOutput = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    764\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    765\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    766\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    767\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    769\u001B[39m last_hidden_state = encoder_outputs.last_hidden_state\n\u001B[32m    770\u001B[39m last_hidden_state = \u001B[38;5;28mself\u001B[39m.post_layernorm(last_hidden_state)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    957\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    958\u001B[39m     return_dict = return_dict_passed\n\u001B[32m--> \u001B[39m\u001B[32m959\u001B[39m output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    961\u001B[39m     output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:594\u001B[39m, in \u001B[36mSiglipEncoder.forward\u001B[39m\u001B[34m(self, inputs_embeds, attention_mask, output_attentions, output_hidden_states)\u001B[39m\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states:\n\u001B[32m    592\u001B[39m     encoder_states = encoder_states + (hidden_states,)\n\u001B[32m--> \u001B[39m\u001B[32m594\u001B[39m layer_outputs = \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    595\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    596\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    597\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    598\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    600\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    602\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001B[39m, in \u001B[36mGradientCheckpointingLayer.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m         logger.warning(message)\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(partial(\u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m, **kwargs), *args)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:450\u001B[39m, in \u001B[36mSiglipEncoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, output_attentions)\u001B[39m\n\u001B[32m    447\u001B[39m residual = hidden_states\n\u001B[32m    449\u001B[39m hidden_states = \u001B[38;5;28mself\u001B[39m.layer_norm1(hidden_states)\n\u001B[32m--> \u001B[39m\u001B[32m450\u001B[39m hidden_states, attn_weights = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    452\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    455\u001B[39m hidden_states = residual + hidden_states\n\u001B[32m    457\u001B[39m residual = hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:389\u001B[39m, in \u001B[36mSiglipAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, **kwargs)\u001B[39m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config._attn_implementation != \u001B[33m\"\u001B[39m\u001B[33meager\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    387\u001B[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001B[38;5;28mself\u001B[39m.config._attn_implementation]\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m attn_output, attn_weights = \u001B[43mattention_interface\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m    \u001B[49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mis_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscaling\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    400\u001B[39m attn_output = attn_output.reshape(batch_size, seq_length, embed_dim).contiguous()\n\u001B[32m    401\u001B[39m attn_output = \u001B[38;5;28mself\u001B[39m.out_proj(attn_output)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:335\u001B[39m, in \u001B[36meager_attention_forward\u001B[39m\u001B[34m(module, query, key, value, attention_mask, scaling, dropout, **kwargs)\u001B[39m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    333\u001B[39m     attn_weights = attn_weights + attention_mask\n\u001B[32m--> \u001B[39m\u001B[32m335\u001B[39m attn_weights = \u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunctional\u001B[49m\u001B[43m.\u001B[49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m.to(query.dtype)\n\u001B[32m    336\u001B[39m attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n\u001B[32m    338\u001B[39m attn_output = torch.matmul(attn_weights, value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/pkg/lib/python3.12/site-packages/torch/nn/functional.py:2142\u001B[39m, in \u001B[36msoftmax\u001B[39m\u001B[34m(input, dim, _stacklevel, dtype)\u001B[39m\n\u001B[32m   2140\u001B[39m     ret = \u001B[38;5;28minput\u001B[39m.softmax(dim)\n\u001B[32m   2141\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2142\u001B[39m     ret = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2143\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 15.60 GiB of which 589.19 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 854.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(\"gemma-supplements-small/final\")\n",
    "writer.close()"
   ]
  }
 ]
}
